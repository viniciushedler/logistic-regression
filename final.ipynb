{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução\n",
    "\n",
    "A Regressão Linear é muito útil, porém não funciona para problemas de classificação. Um problema de classificação é quando se deseja classificar um objeto em uma de várias categorias através de uma ou mais características que se sabe sobre o objeto. \n",
    "\n",
    "Um exemplo simples deste tipo de problema é quando se deseja prever se uma pessoa é ou não obesa apenas sabendo seu peso. O gráfico abaixo contém as ocorrências de 80 pessoas que possuem um determinado peso e podem ou não ser obesas.\n",
    "\n",
    "![Gráfico de Dispersão](images\\grafico1.jpeg)\n",
    "\n",
    "Aplicando uma regressão linear, prevê-se para algumas pessoas uma probabilidade maior que 1, oque é impossível.\n",
    "\n",
    "![Regressão linear aplicada ao gráfico](images\\grafico2.jpeg)\n",
    "\n",
    "Para evitar isso, projeta-se uma regressão logística, que produz um resultado mais adequado.\n",
    "\n",
    "\n",
    "![Regressão logística aplicada ao gráfico](images\\grafico3.jpeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Como funciona\n",
    "A regressão logística é versão da regressão linear adequada a problemas de classificação. Para se adequar à este tipo de problema ao invés de prever quanto algo vai ser em uma escala contínua, a regressão logística prevê a probabilidade de algo se encaixar em uma categoria. Esta probabilidade, como qualquer outra, varia entre 0 e 1. para se manter dentro do contradomínio, a regressão logística usa a função Sigmóide:\n",
    "\n",
    "$y = \\frac{1}{1+e^{-f(x)}}$\n",
    "\n",
    "A função Sigmóide tem o seu formato definido pela função $f(x)$, ou seja, para adequar a função logística do jeito desejado é necessário alterar a função $f(x)$. Uma função $f(x)$ simples utilizada na regressão logística é a seguinte função linear:\n",
    "\n",
    "$f(x) = w_0 + w_1x_1 + w_2x_2 + ... + w_nx_n$,\n",
    "\n",
    "onde cada $x_i$ é uma característica sendo observada e cada $w_i$ é um peso atribuido à característica $x_i$. Também são definidos $X_{n\\times 1} = [1, x_1, ..., x_n]$ e $W_{n\\times 1} = [w_0, w_1, ..., w_n]$. Assim sendo, tem-se que $f(x) = W^TX$\n",
    "\n",
    "Para já acostumar o leitor, vamos escrever a função Sigmóide da forma como ela será usada mais à frente:\n",
    "\n",
    "$ p(X) = \\frac{1}{1+e^{- W^T X}} $\n",
    "\n",
    "Dessa forma, o objetivo se torna encontrar a matriz $W$ que gera os resultados mais próximos do esperado.\n",
    "\n",
    "Fica claro que há casos onde $p(X)$ (valor previsto) é igual ao $y$ (valor real). Uma das formas de calcular o acerto é através da fórmula de  INSERT (Máxima Verosemelhança?) NOME. Ela funciona da seguinte forma:\n",
    "\n",
    "\n",
    "1 Separa os objetos em objetos com $y=1$ e objetos com $y=0$. O $X$ de cada determinado objeto será aqui chamado apenas de $X$\n",
    "2 Para objetos com $y=1$, busca-se $W$ tal que $p(X)$ fique o mais próximo possível de 1\n",
    "3 Para objetos com $y=0$, busca-se $W$ tal que $p(X)$ fique o mais próximo possível de 0\n",
    "3* Em outras palavras, para objetos com $y=0$ busca-se $W$ tal que $1-p(X)$ fique o mais próximo possível de 1\n",
    "4 Ao se acumular as probabilidades, temos o produtório de ambos objetos com $y=1$ ou $y=0$ deve ser igual a 1 da seguinte forma:\n",
    "\n",
    "$ \\prod p(x) $ para $y=1$ e $ \\prod (1-p(x)) $ para $y=0$\n",
    "\n",
    "5 É possível juntar os dois produtórios, aplicando um expoente $y$ ou $y-1$ à cada um. O papel deste expoente é garantir que quando cada produtório somente tenha impacto quando for aplicável:\n",
    "\n",
    "$ L(W) = \\prod p(x)^{y}(1-p(x))^{(1-y)} $\n",
    "\n",
    "note que $y=1 \\implies (1-p(x))^{(1-y)}=1$ e $y=0 \\implies p(x)^y=1$\n",
    "\n",
    "Esta é função permite avaliar quão boa é a matriz $W$. Portanto, ao se maximizar esta função se otimiza a regressão logística! \n",
    "\n",
    "6 É possível trabalhar esta função aplicando $\\log{}$, que então transforma o produtório em somatório:\n",
    "\n",
    "$ \\log{L(W)} = \\log({\\prod p(X)^{y}(1-p(X))^{(1-y)}}) $\n",
    "\n",
    "$ l(W) = \\sum y\\log{p(X)}+(1-y)\\log({1-p(X)}) $\n",
    "\n",
    "7 Para continuar, é necessário expandir $p(X)$:\n",
    "\n",
    "$ l(W) = \\sum y\\log{\\frac{1}{1+e^{- W^T X}}}+(1-y)\\log({1-\\frac{1}{1+e^{- W^T X}}}) = \\sum y\\log{\\frac{1}{1+e^{- W^T X}}}+(1-y)\\log({\\frac{e^{- W^T X}}{1+e^{- W^T X}}})$\n",
    "\n",
    "8 Efetua-se a multiplicação $(1-y)\\log({\\frac{e^{- W^T X}}{1+e^{- W^T X}}})$:\n",
    "\n",
    "$ \\sum y\\log{\\frac{1}{1+e^{- W^T X}}}-y\\log({\\frac{e^{- W^T X}}{1+e^{- W^T X}}}) + \\log({\\frac{e^{- W^T X}}{1+e^{- W^T X}}}) $\n",
    "\n",
    "9 Agrupa-se onde há coeficiente $y$:\n",
    "\n",
    "$ \\sum y[\\log{\\frac{1}{1+e^{- W^T X}}}-\\log({\\frac{e^{- W^T X}}{1+e^{- W^T X}}})] + \\log({\\frac{e^{- W^T X}}{1+e^{- W^T X}}}) $ \n",
    "\n",
    "10 Utiliza-se a propriedade da subtração de dois logarítmos:\n",
    "\n",
    "$ \\sum y\\log({\\frac{1}{1+e^{- W^T X}}} * {\\frac{1+e^{- W^T X}}{e^{- W^T X}}}) + \\log({\\frac{e^{- W^T X}}{1+e^{- W^T X}}}) = \\sum y\\log({\\frac{1}{e^{- W^T X}}}) + \\log({\\frac{e^{- W^T X}}{1+e^{- W^T X}}})$ \n",
    "\n",
    "11 Altera-se as funções dentro dos logarítmos mantendo a igualdade:\n",
    "\n",
    "$ \\sum y\\log({\\frac{1}{e^{W^T X}}^{-1}}) + \\log({\\frac{e^{- W^T X}}{1+e^{- W^T X} \\prod \\frac{e^{W^T X}}{e^{W^T X}} }})  = \\sum y\\log({e^{W^T X}}) + \\log({\\frac{1}{1+e^{W^T X}}}) $\n",
    "\n",
    "12 Finalizando:\n",
    "\n",
    "$ l(W) = \\sum yW^T X - \\log({1+e^{W^T X}}) $ \n",
    "\n",
    "Assim, busca-se encontrar $W$ que maximiza $l(W)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo\n",
    "\n",
    "Idealmente seria possível encontrar o máximo de $l(W)$ de maneira \"simples\", porém a função em questão não é algébrica e sim transcendental. Isto ocorre por causa da função $\\log{}$, e significa que não é possível calcular seu máximo de maneira exata e \"instantânea\". Contudo existem métodos de aproximação, e o método aqui mostrado será o Método de Newton Raphson.\n",
    "\n",
    "O Método de Newton Raphson atua começando com uma variável independente arbitrária e então encontrando um novo valor para esta variável independente através da divisão do valor da função sendo analisada pela sua derivada:\n",
    "\n",
    "$  x_{n+1} = x_n- \\frac{\\partial f(x_n)}{\\partial f(x_n)}$\n",
    "\n",
    "Ou seja, dado um $W_n$, haverá um $W_{n+1}=W_n + gradiente$. Assim sendo, a equação que precisa ser iterada para encontrar o valor desejado para $W$ é:\n",
    "\n",
    "$ W_{n+1} = (X^TW_nX)^{-1}X(Y-\\hat{Y_n}) $,\n",
    "\n",
    "onde $W_n$ são os parâmetros na iteração $n$, $X$ são as características sendo observadas, $Y$ é o valor de $y$ e $\\hat{Y}_n$ é o valor previsto para $y$.\n",
    "\n",
    "Assim, se começa com um $W$ arbitrário (comumente $W=1$) e então se caminha até chegar em um resultado satisfatório"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rodando o algoritmo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrindo base de dados\n",
    "df = pd.read_csv(\"diabetes.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escolhendo quais serão as variáveis independentes e a variável dependente sendo observada (Outcome)\n",
    "\n",
    "X = df.iloc[:, df.columns!=\"Outcome\"]\n",
    "y = df[\"Outcome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rodando o algorítmo\n",
    "lr = LogisticRegression(random_state=0, max_iter=1000).fit(df.loc[:, df.columns!=\"Outcome\"], df[\"Outcome\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o y esperado\n",
    "y_esperado = lr.predict(X.loc[:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a probabilidade de y\n",
    "y_prob = lr.predict_proba(X.loc[:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78125"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precisão do algoritmo\n",
    "lr.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>y_esperado</th>\n",
       "      <th>y_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.280566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.950709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.207430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.957268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.110349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.676247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.678678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.713206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.926945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  y_esperado    y_prob  \n",
       "0                       0.627   50        1           1  0.280566  \n",
       "1                       0.351   31        0           0  0.950709  \n",
       "2                       0.672   32        1           1  0.207430  \n",
       "3                       0.167   21        0           0  0.957268  \n",
       "4                       2.288   33        1           1  0.110349  \n",
       "..                        ...  ...      ...         ...       ...  \n",
       "763                     0.171   63        0           0  0.676247  \n",
       "764                     0.340   27        0           0  0.678678  \n",
       "765                     0.245   30        0           0  0.826970  \n",
       "766                     0.349   47        1           0  0.713206  \n",
       "767                     0.315   23        0           0  0.926945  \n",
       "\n",
       "[768 rows x 11 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_df = pd.concat([X,y], axis=1)\n",
    "n_df[\"y_esperado\"] = y_esperado\n",
    "n_df[\"y_prob\"] = [y[0] for y in y_prob]\n",
    "n_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusão\n",
    "\n",
    "O algoritmo teve uma precisão de 78%"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
